{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and read file\n",
    "with open('ruscorpora_upos_skipgram_300_5_2018.vec', encoding='utf-8') as f: #НКРЯ\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195072"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length of file \n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of words in the word embedding\n",
    "words = [lines[i].split()[0] for i in range(1, len(lines))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file of chosen professions\n",
    "\n",
    "import pandas as pd\n",
    "df_prof = pd.read_csv('./professions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Я ОЧЕНЬ РЕКОМЕНДИЮ НАЗВАТЬ ЭТО professions_list\n",
    "search_list = []\n",
    "for word in words:\n",
    "    for prof in set(df_prof['профессии']):\n",
    "        if word == prof + '_NOUN':\n",
    "            search_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to make a matrix out of the list of strings\n",
    "import numpy as np\n",
    "\n",
    "lines_formatrix = lines[1:]\n",
    "words_list = []\n",
    "for i in range(len(lines_formatrix)):\n",
    "    split_line = lines_formatrix[i].split(' ', 1)\n",
    "    words_list.append(split_line[0])\n",
    "    lines_formatrix[i] = split_line[1]\n",
    "    \n",
    "E = np.loadtxt(lines_formatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195071, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the indexes of the profession (from the professions cvx) in the word embedding matrix\n",
    "ind_prof = []\n",
    "for i in range(len(words_list)):\n",
    "    for elem in search_list:\n",
    "        if elem == words_list[i]:\n",
    "            ind_prof.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(459, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create P matrix of vectors for the professions\n",
    "P = E[ind_prof,:]\n",
    "\n",
    "# check the shape of P \n",
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.41463988 2.04141369 1.96470187 1.89613182 1.73493755 1.56332096\n",
      " 1.53138261 1.49973152 1.412821   1.34707082]\n"
     ]
    }
   ],
   "source": [
    "# try to use male-female word pairs to get gender axis\n",
    "# open and preprocess word pairs\n",
    "with open('word_pairs.txt','r', encoding = 'utf-8') as of:\n",
    "    word_pairs = of.readlines()\n",
    "    \n",
    "for i in range(len(word_pairs)):\n",
    "    word_pairs[i] = word_pairs[i].strip()\n",
    "word_pairs[0] = 'мужчина_NOUN'   \n",
    "\n",
    "# find the indexes of these word pairs in the embedding matrix\n",
    "ind_nouns = []\n",
    "for i in range(len(words_list)):\n",
    "    for elem in word_pairs:        \n",
    "        if elem == words_list[i]:\n",
    "            ind_nouns.append(i)\n",
    "            \n",
    "# separate indexes for male and female nouns\n",
    "ind_male_noun = []\n",
    "ind_female_noun = []\n",
    "for i in range(len(ind_nouns)):\n",
    "    if i % 2 == 0:\n",
    "        ind_male_noun.append(ind_nouns[i])\n",
    "    if i % 2 != 0:\n",
    "        ind_female_noun.append(ind_nouns[i])\n",
    "        \n",
    "# make male and female matrix\n",
    "male_matrix = E[ind_male_noun,:]\n",
    "female_matrix = E[ind_female_noun,:]\n",
    "\n",
    "# find the difference matrix (for the gender axis) and the use PCA to find the main principle component\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "difference_matrix = male_matrix - female_matrix\n",
    "pca = PCA(n_components = 10)\n",
    "pca_forprojection = pca.fit(difference_matrix)\n",
    "gender_axis_pca = pca_forprojection.components_[0]\n",
    "\n",
    "# check the singular value decay\n",
    "singular_values = pca_forprojection.singular_values_\n",
    "print(singular_values)\n",
    "# the singular value decay is not good, so we will use just man-woman vector for gender axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find vectors for мужчина и женщина\n",
    "ind_man = words_list.index('мужчина_NOUN')\n",
    "ind_woman = words_list.index('женщина_NOUN')\n",
    "\n",
    "man = E[ind_man, :]\n",
    "woman = E[ind_woman, :]\n",
    "# b vector is gender axis\n",
    "b = man - woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find projections of professions onto gender axis\n",
    "projections = []\n",
    "gender_axis_norm = (b)/np.linalg.norm(b) # normalized gender axis\n",
    "\n",
    "for i in range(P.shape[0]):\n",
    "    proj = np.dot(P[i,:], gender_axis_norm)\n",
    "    projections.append(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of projections\n",
    "\n",
    "\n",
    "# НАСТЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the bounds for extreme professions\n",
    "right_bound = np.mean(projections) + 1.5*np.std(projections)\n",
    "left_bound = np.mean(projections) - 1*np.std(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "губернатор_NOUN\n",
      "водитель_NOUN\n",
      "мэр_NOUN\n",
      "охранник_NOUN\n",
      "менеджер_NOUN\n",
      "распорядитель_NOUN\n",
      "счетчик_NOUN\n",
      "испытатель_NOUN\n",
      "декан_NOUN\n",
      "метрдотель_NOUN\n",
      "экспедитор_NOUN\n",
      "брокер_NOUN\n",
      "монтажник_NOUN\n",
      "калькулятор_NOUN\n",
      "сплавщик_NOUN\n",
      "шеф-повар_NOUN\n",
      "гардеробщик_NOUN\n",
      "крупье_NOUN\n",
      "униформист_NOUN\n",
      "заготовитель_NOUN\n",
      "собаковод_NOUN\n",
      "охотовед_NOUN\n",
      "заправщик_NOUN\n",
      "переработчик_NOUN\n",
      "букмекер_NOUN\n",
      "подносчик_NOUN\n",
      "трубник_NOUN\n",
      "шеф-редактор_NOUN\n",
      "паспортист_NOUN\n",
      "перегонщик_NOUN\n",
      "демонстратор_NOUN\n",
      "вальщик_NOUN\n"
     ]
    }
   ],
   "source": [
    "# find and print the extreme professions for both male\n",
    "\n",
    "ind_var_male = []\n",
    "for i in range(len(projections)):\n",
    "    if projections[i] > right_bound:\n",
    "        ind_var_male.append(i)\n",
    "        \n",
    "for i in ind_var_male:\n",
    "    print(search_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "губернатор_NOUN\n",
      "водитель_NOUN\n",
      "мэр_NOUN\n",
      "охранник_NOUN\n",
      "менеджер_NOUN\n",
      "распорядитель_NOUN\n",
      "счетчик_NOUN\n",
      "испытатель_NOUN\n",
      "декан_NOUN\n",
      "метрдотель_NOUN\n",
      "экспедитор_NOUN\n",
      "брокер_NOUN\n",
      "монтажник_NOUN\n",
      "калькулятор_NOUN\n",
      "сплавщик_NOUN\n",
      "шеф-повар_NOUN\n",
      "гардеробщик_NOUN\n",
      "крупье_NOUN\n",
      "униформист_NOUN\n",
      "заготовитель_NOUN\n",
      "собаковод_NOUN\n",
      "охотовед_NOUN\n",
      "заправщик_NOUN\n",
      "переработчик_NOUN\n",
      "букмекер_NOUN\n",
      "подносчик_NOUN\n",
      "трубник_NOUN\n",
      "шеф-редактор_NOUN\n",
      "паспортист_NOUN\n",
      "перегонщик_NOUN\n",
      "демонстратор_NOUN\n",
      "вальщик_NOUN\n"
     ]
    }
   ],
   "source": [
    "# find and print the extreme professions for both male\n",
    "\n",
    "ind_var_male = []\n",
    "for i in range(len(projections)):\n",
    "    if projections[i] > right_bound:\n",
    "        ind_var_male.append(i)\n",
    "        \n",
    "for i in ind_var_male:\n",
    "    print(search_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сестра_NOUN\n",
      "художник_NOUN\n",
      "врач_NOUN\n",
      "учитель_NOUN\n",
      "специалист_NOUN\n",
      "мастер_NOUN\n",
      "инженер_NOUN\n",
      "губернатор_NOUN\n",
      "матрос_NOUN\n",
      "водитель_NOUN\n",
      "комиссар_NOUN\n",
      "сторож_NOUN\n",
      "педагог_NOUN\n",
      "организатор_NOUN\n",
      "мэр_NOUN\n",
      "наблюдатель_NOUN\n",
      "повар_NOUN\n",
      "посланник_NOUN\n",
      "охранник_NOUN\n",
      "няня_NOUN\n",
      "смотритель_NOUN\n",
      "менеджер_NOUN\n",
      "живописец_NOUN\n",
      "фельдшер_NOUN\n",
      "скульптор_NOUN\n",
      "хранитель_NOUN\n",
      "садовник_NOUN\n",
      "почтальон_NOUN\n",
      "казначей_NOUN\n",
      "конюх_NOUN\n",
      "распорядитель_NOUN\n",
      "ювелир_NOUN\n",
      "счетчик_NOUN\n",
      "испытатель_NOUN\n",
      "машинистка_NOUN\n",
      "акушерка_NOUN\n",
      "маляр_NOUN\n",
      "библиотекарь_NOUN\n",
      "санитарка_NOUN\n",
      "декан_NOUN\n",
      "кинорежиссер_NOUN\n",
      "реставратор_NOUN\n",
      "метрдотель_NOUN\n",
      "корректор_NOUN\n",
      "экспедитор_NOUN\n",
      "швея_NOUN\n",
      "брокер_NOUN\n",
      "монтажник_NOUN\n",
      "балетмейстер_NOUN\n",
      "метеоролог_NOUN\n",
      "стенографистка_NOUN\n",
      "калькулятор_NOUN\n",
      "сплавщик_NOUN\n",
      "рисовальщик_NOUN\n",
      "статс-секретарь_NOUN\n",
      "радиотехник_NOUN\n",
      "пчеловод_NOUN\n",
      "печатник_NOUN\n",
      "модистка_NOUN\n",
      "шеф-повар_NOUN\n",
      "юрисконсульт_NOUN\n",
      "медник_NOUN\n",
      "гравер_NOUN\n",
      "гончар_NOUN\n",
      "гардеробщик_NOUN\n",
      "крупье_NOUN\n",
      "переплетчик_NOUN\n",
      "цветочница_NOUN\n",
      "униформист_NOUN\n",
      "минералог_NOUN\n",
      "заготовитель_NOUN\n",
      "кастелянша_NOUN\n",
      "смазчик_NOUN\n",
      "библиограф_NOUN\n",
      "обойщик_NOUN\n",
      "гидротехник_NOUN\n",
      "почвовед_NOUN\n",
      "точильщик_NOUN\n",
      "собаковод_NOUN\n",
      "геохимик_NOUN\n",
      "охотовед_NOUN\n",
      "кружевница_NOUN\n",
      "заправщик_NOUN\n",
      "хормейстер_NOUN\n",
      "виноградарь_NOUN\n",
      "вышивальщица_NOUN\n",
      "переработчик_NOUN\n",
      "букмекер_NOUN\n",
      "подносчик_NOUN\n",
      "трубник_NOUN\n",
      "чеканщик_NOUN\n",
      "шеф-редактор_NOUN\n",
      "паспортист_NOUN\n",
      "перегонщик_NOUN\n",
      "колорист_NOUN\n",
      "демонстратор_NOUN\n",
      "сестра-хозяйка_NOUN\n",
      "лудильщик_NOUN\n",
      "свиновод_NOUN\n",
      "ламповщик_NOUN\n",
      "вальщик_NOUN\n",
      "чаевод_NOUN\n"
     ]
    }
   ],
   "source": [
    "# find and the extreme professions for both male and female\n",
    "\n",
    "ind_var = []\n",
    "for i in range(len(projections)):\n",
    "    if projections[i] < left_bound or projections[i] >  right_bound:\n",
    "        ind_var.append(i)\n",
    "        \n",
    "for i in ind_var:\n",
    "    print(search_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file with selected extreme professions\n",
    "with open('professions_for_selection','w',encoding = 'utf-8') as of:\n",
    "    for i in ind_var:\n",
    "        of.write(search_list[i] + '\\n')\n",
    "    of.close()\n",
    "    \n",
    "with open('professions_after_selection','r', encoding = 'utf-8') as of:\n",
    "    slist_rev = of.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЧТО ЭТО?\n",
    "for i in range(len(slist_rev)):\n",
    "    slist_rev[i] = slist_rev[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И ЭТО ЧТО?\n",
    "ind_prof_rev = []                          #чтобы достать индексы профессий уже отобранных, тот же код здесь!\n",
    "for i in range(len(words_list)):\n",
    "    for elem in slist_rev:\n",
    "        if elem == words_list[i]:\n",
    "            ind_prof_rev.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of the words in the words list that do not need to be in A\n",
    "ind_prof_rev_forA = ind_prof_rev\n",
    "ind_prof_rev_forA.append(words_list.index('мужчина_NOUN'))\n",
    "ind_prof_rev_forA.append(words_list.index('женщина_NOUN'))\n",
    "\n",
    "words_list_forA = [v for i, v in enumerate(words_list) if i not in ind_prof_rev_forA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make A by deleting extreme professions and man and woman vectors\n",
    "A = np.delete(E, ind_prof_rev_forA, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195007, 300)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the revised indexes are of the correct length\n",
    "len(ind_prof_rev_forA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make P out of the extreme professions\n",
    "P_rev= E[ind_prof_rev,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD \n",
    "u, s, vt = np.linalg.svd(A, full_matrices = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save SVD matrices\n",
    "import pickle\n",
    "\n",
    "with open('matrix_s', 'wb') as f:\n",
    "        pickle.dump(s, f)\n",
    "        \n",
    "with open('matrix_vt', 'wb') as f:\n",
    "        pickle.dump(vt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape B for optimization\n",
    "B_reshaped = b.reshape((1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EK\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py:661: RuntimeWarning: overflow encountered in long_scalars\n",
      "  if self.max_big_small_squared < big*small**2:\n",
      "C:\\Users\\EK\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py:662: RuntimeWarning: overflow encountered in long_scalars\n",
      "  self.max_big_small_squared = big*small**2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "\tSCS v2.0.2 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012-2017\n",
      "----------------------------------------------------------------------------\n",
      "Lin-sys: sparse-indirect, nnz in A = 32805158, CG tol ~ 1/iter^(2.00)\n",
      "eps = 1.00e-05, alpha = 1.50, max_iters = 300, normalize = 1, scale = 1.00\n",
      "acceleration_lookback = 20, rho_x = 1.00e-03\n",
      "Variables n = 90004, constraints m = 135222\n",
      "Cones:\tsoc vars: 90072, soc blks: 4\n",
      "\tsd vars: 45150, sd blks: 1\n",
      "Setup time: 4.61e+00s\n",
      "----------------------------------------------------------------------------\n",
      " Iter | pri res | dua res | rel gap | pri obj | dua obj | kap/tau | time (s)\n",
      "----------------------------------------------------------------------------\n",
      "     0| 1.42e+00  1.37e+00  9.83e-01 -5.29e+01  4.98e+00  1.30e-14  5.28e+01 \n",
      "   100| 4.32e-03  3.68e-03  3.85e-03  3.19e-02  2.78e-02  9.28e-16  1.07e+03 \n",
      "   200| 2.83e-03  3.49e-03  2.86e-03  2.84e-02  3.14e-02  3.79e-15  2.44e+03 \n",
      "   300| 2.71e-03  5.94e-03  1.52e-03  3.08e-02  3.24e-02  6.36e-15  3.93e+03 \n",
      "----------------------------------------------------------------------------\n",
      "Status: Solved/Inaccurate\n",
      "Hit max_iters, solution may be inaccurate\n",
      "Timing: Solve time: 3.93e+03s\n",
      "\tLin-sys: avg # CG iterations: 77.57, avg solve time: 1.30e+01s\n",
      "\tCones: avg projection time: 6.54e-03s\n",
      "\tAcceleration: avg step time: 3.96e-02s\n",
      "----------------------------------------------------------------------------\n",
      "Error metrics:\n",
      "dist(s, K) = 7.2267e-05, dist(y, K*) = 5.1102e-07, s'y/|s||y| = -3.2860e-08\n",
      "primal res: |Ax + s - b|_2 / (1 + |b|_2) = 2.7118e-03\n",
      "dual res:   |A'y + c|_2 / (1 + |c|_2) = 5.9412e-03\n",
      "rel gap:    |c'x + b'y| / (1 + |c'x| + |b'y|) = 1.5220e-03\n",
      "----------------------------------------------------------------------------\n",
      "c'x = 0.0308, -b'y = 0.0324\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZATION\n",
    "import cvxpy as cp\n",
    "\n",
    "lam = 0.2\n",
    "S = np.diag(s)\n",
    "I = np.eye(300)\n",
    "\n",
    "X = cp.Variable((300,300))\n",
    "\n",
    "constraints = [X >> 0]\n",
    "\n",
    "obj = cp.Minimize(cp.norm((S* vt *(X - I)* vt.T* S), \"fro\")**2 + lam*(cp.norm(((P_rev * X) * B_reshaped.T), 'fro')**2))\n",
    "\n",
    "\n",
    "prob = cp.Problem(obj, constraints)\n",
    "result = prob.solve(verbose=True, max_iters = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE REST OF THE CODE IS FOR GRAPHS FOR THE PRESENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_biased = []\n",
    "ind_biased.append(words_list.index('губернатор_NOUN'))\n",
    "ind_biased.append(words_list.index('менеджер_NOUN'))\n",
    "ind_biased.append(words_list.index('шеф-повар_NOUN'))\n",
    "\n",
    "ind_biased.append(words_list.index('учитель_NOUN'))\n",
    "ind_biased.append(words_list.index('повар_NOUN'))\n",
    "ind_biased.append(words_list.index('библиотекарь_NOUN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_biased = E[ind_biased]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_biased = []\n",
    "for i in range(len(P_biased)):\n",
    "    proj = np.dot(P_biased[i,:], gender_axis)\n",
    "    projections_biased.append(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09399251928692341,\n",
       " 0.10277682969215783,\n",
       " 0.08744104518808561,\n",
       " -0.10764189415477886,\n",
       " -0.09881289270342167,\n",
       " -0.08984160394928667]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections_biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_non_biased = []\n",
    "ind_non_biased.append(words_list.index('стол_NOUN'))\n",
    "ind_non_biased.append(words_list.index('дверь_NOUN'))\n",
    "ind_non_biased.append(words_list.index('солнце_NOUN'))\n",
    "ind_non_biased.append(words_list.index('разница_NOUN'))\n",
    "ind_non_biased.append(words_list.index('картошка_NOUN'))\n",
    "ind_non_biased.append(words_list.index('каникулы_NOUN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_non_biased = E[ind_non_biased]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_non_biased = []\n",
    "for i in range(len(P_non_biased)):\n",
    "    proj = np.dot(P_non_biased[i,:], gender_axis)\n",
    "    projections_non_biased.append(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.026983462075943522,\n",
       " 0.010604005992281888,\n",
       " -0.056614574222124216,\n",
       " 0.03903067615755927,\n",
       " 0.0056370858875865034,\n",
       " -0.028937789834120247]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections_non_biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
