{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import cvxpy as cp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and read file\n",
    "with open('ruscorpora_upos_skipgram_300_5_2018.vec', encoding='utf-8') as f: #НКРЯ\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195072"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length of file \n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of words in the word embeddings\n",
    "words = [lines[i].split()[0] for i in range(1, len(lines))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file of chosen professions (\"ГАРАНТ system\")\n",
    "\n",
    "df_prof = pd.read_csv('./professions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full list of professions which we found in our corpus (professions for which we have word embeddings)\n",
    "professions_list = []\n",
    "for word in words:\n",
    "    for prof in set(df_prof['профессии']):\n",
    "        if word == prof + '_NOUN':\n",
    "            professions_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to make a matrix out of the list of strings\n",
    "\n",
    "lines_formatrix = lines[1:]\n",
    "words_list = []\n",
    "for i in range(len(lines_formatrix)):\n",
    "    split_line = lines_formatrix[i].split(' ', 1)\n",
    "    words_list.append(split_line[0])\n",
    "    lines_formatrix[i] = split_line[1]\n",
    "    \n",
    "E = np.loadtxt(lines_formatrix)       #it is a matrix with all word embeddings from our model RNC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the indexes of the profession (from the professions.csv) in the word embedding matrix\n",
    "ind_prof = [i for i in range(len(words_list)) if words_list[i] in professions_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create P matrix of vectors for the professions\n",
    "P = E[ind_prof,:]\n",
    "\n",
    "# check the shape of P \n",
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to use male-female word pairs to get gender axis\n",
    "# open and preprocess word pairs\n",
    "with open('word_pairs.txt','r', encoding = 'utf-8') as of:\n",
    "    word_pairs = of.readlines()\n",
    "    \n",
    "for i in range(len(word_pairs)):\n",
    "    word_pairs[i] = word_pairs[i].strip()\n",
    "word_pairs[0] = 'мужчина_NOUN'   \n",
    "\n",
    "# find the indexes of these word pairs in the embedding matrix\n",
    "ind_nouns = []\n",
    "for i in range(len(words_list)):\n",
    "    for elem in word_pairs:        \n",
    "        if elem == words_list[i]:\n",
    "            ind_nouns.append(i)\n",
    "            \n",
    "# separate indexes for male and female nouns\n",
    "ind_male_noun = []\n",
    "ind_female_noun = []\n",
    "for i in range(len(ind_nouns)):\n",
    "    if i % 2 == 0:\n",
    "        ind_male_noun.append(ind_nouns[i])\n",
    "    if i % 2 != 0:\n",
    "        ind_female_noun.append(ind_nouns[i])\n",
    "        \n",
    "# make male and female matrix\n",
    "male_matrix = E[ind_male_noun,:]\n",
    "female_matrix = E[ind_female_noun,:]\n",
    "\n",
    "# find the difference matrix (for the gender axis) and the use PCA to find the main principle component\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "difference_matrix = male_matrix - female_matrix\n",
    "pca = PCA(n_components = 10)\n",
    "pca_forprojection = pca.fit(difference_matrix)\n",
    "gender_axis_pca = pca_forprojection.components_[0]\n",
    "\n",
    "# check the singular value decay\n",
    "singular_values = pca_forprojection.singular_values_\n",
    "print(singular_values)\n",
    "# the singular value decay is not good, so we will use just man-woman vector for gender axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find vectors for мужчина и женщина\n",
    "ind_man = words_list.index('мужчина_NOUN')\n",
    "ind_woman = words_list.index('женщина_NOUN')\n",
    "\n",
    "man = E[ind_man, :]\n",
    "woman = E[ind_woman, :]\n",
    "# b vector is gender axis\n",
    "b = man - woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find projections of professions onto gender axis\n",
    "\n",
    "def find_proj(P, b):\n",
    "    projections = []\n",
    "    gender_axis_norm = (b)/np.linalg.norm(b) # normalized gender axis\n",
    "\n",
    "    for i in range(P.shape[0]):\n",
    "        proj = np.dot(P[i,:], gender_axis_norm)\n",
    "        projections.append(proj)\n",
    "    return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of projections\n",
    "\n",
    "projections = find_proj(P, b)\n",
    "\n",
    "plt.hist(projections)\n",
    "plt.title('Projections of professions onto man-woman direction', size =14 )\n",
    "plt.xlabel(' '*10 + '<---- woman' + ' '*20 + ' ----> man', size = 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the bounds for extreme professions\n",
    "right_bound = np.mean(projections) + 1.5*np.std(projections)\n",
    "left_bound = np.mean(projections) - 1*np.std(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and print the extreme professions for both male\n",
    "\n",
    "ind_var_male = []\n",
    "for i in range(len(projections)):\n",
    "    if projections[i] > right_bound:\n",
    "        ind_var_male.append(i)\n",
    "        \n",
    "for i in ind_var_male:\n",
    "    print(professions_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and the extreme professions for both male and female\n",
    "\n",
    "ind_var = []\n",
    "for i in range(len(projections)):\n",
    "    if projections[i] < left_bound or projections[i] >  right_bound:\n",
    "        ind_var.append(i)\n",
    "        \n",
    "for i in ind_var:\n",
    "    print(professions_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file with selected extreme professions\n",
    "with open('professions_for_selection','w',encoding = 'utf-8') as of:\n",
    "    for i in ind_var:\n",
    "        of.write(professions_list[i] + '\\n')\n",
    "    of.close()\n",
    "    \n",
    "with open('professions_after_selection','r', encoding = 'utf-8') as of:\n",
    "    slist_rev = of.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of professions after selection (63 professions)\n",
    "slist_rev = [slist_rev[i].strip() for i in range(len(slist_rev)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slist_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices in words_list of 63 chosen professions\n",
    "ind_prof_rev = [i for i in range(len(words_list)) if words_list[i] in slist_rev]                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make A by deleting the extreme professions and man and woman vectors\n",
    "A = np.delete(E, ind_prof_rev+[ind_man]+[ind_woman], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make P out of the extreme professions\n",
    "P_rev= E[ind_prof_rev,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD \n",
    "u, s, vt = np.linalg.svd(A, full_matrices = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save SVD matrices\n",
    "\n",
    "with open('matrix_s', 'wb') as f:\n",
    "        pickle.dump(s, f)\n",
    "        \n",
    "with open('matrix_vt', 'wb') as f:\n",
    "        pickle.dump(vt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you don't have memory for computing SVD you can load them\n",
    "with open('matrix_s', 'rb') as f:\n",
    "    s = pickle.load(f)\n",
    "\n",
    "with open('matrix_vt', 'rb') as f:\n",
    "    vt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape B for optimization\n",
    "B_reshaped = b.reshape((1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZATION\n",
    "\n",
    "lam = 0.2\n",
    "S = np.diag(s)\n",
    "I = np.eye(300)\n",
    "\n",
    "X = cp.Variable((300,300))\n",
    "\n",
    "constraints = [X >> 0]\n",
    "\n",
    "obj = cp.Minimize(cp.norm((S* vt *(X - I)* vt.T* S), \"fro\")**2 + lam*(cp.norm(((P_rev * X) * B_reshaped.T), 'fro')**2))\n",
    "\n",
    "\n",
    "prob = cp.Problem(obj, constraints)\n",
    "result = prob.solve(verbose=True, max_iters = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res = X.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cholesky decompostion for finding transformation matrix T\n",
    "T = np.linalg.cholesky(X_res)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result validation\n",
    "b_after_T = T.T @ b.T\n",
    "\n",
    "print('standard derivation of extreme professions before transformation: ', np.round(np.std(find_proj(P_rev, b)),2))\n",
    "print('standard derivation of extreme professions after transformation: ', np.round(np.std(find_proj(P_rev @ T, b_after_T)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE REST OF THE CODE IS FOR GRAPHS FOR THE PRESENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wforValid = ['губернатор_NOUN','менеджер_NOUN','шеф-повар_NOUN',\n",
    "             'учитель_NOUN','повар_NOUN','библиотекарь_NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_biased = [words_list.index(word) for word in wforValid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_biased = E[ind_biased]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_biased = find_proj(P_biased, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "projections_biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_debiased = [slist_rev.index(word) for word in wforValid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_debiased = (P_rev @ T)[ind_debiased]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_debiased = find_proj(P_debiased, b_after_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
